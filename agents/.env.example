# Ollama Configuration
# Base URL for Ollama API (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Ollama Model to use
# Popular options: llama3.2, llama3.3, codellama, mistral, mixtral, qwen
OLLAMA_MODEL=llama3.2

# Agent Configuration
DEFAULT_TEMPERATURE=0.5
DEFAULT_MAX_TOKENS=4096

# Paths (optional, defaults to parent directory)
# DESIGN_SYSTEM_PATH=../
# COMPONENTS_PATH=../components
# DOCS_PATH=../docs
